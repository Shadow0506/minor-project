# Multi-Robot Reinforcement Learning Simulation in ARGoS

## ğŸ¯ Project Overview

This project implements a Deep Q-Learning system where 4 FootBots learn to navigate to a goal while avoiding collisions in a 20Ã—20m arena using ARGoS3 as the physics simulator.

## ğŸ—ï¸ Architecture

```
Sensors â†’ Q-Network â†’ Action â†’ ARGoS Environment â†’ Reward â†’ Q-Update
```

### Component Flow:
1. **ARGoS**: Simulates physics, robot movement, and collision detection
2. **C++ Controller**: Collects sensor data, communicates with Python Q-Network
3. **Python Q-Network**: Makes decisions, learns from rewards
4. **Communication**: Socket-based IPC between C++ and Python

## ğŸ“ Project Structure

```
project_files/
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ BUILD_INSTRUCTIONS.md          # Detailed build guide
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ q_swarm_controller/
â”‚   â”‚   â”œâ”€â”€ q_swarm_controller.h   # Controller header
â”‚   â”‚   â”œâ”€â”€ q_swarm_controller.cpp # Controller implementation
â”‚   â”‚   â””â”€â”€ CMakeLists.txt         # Build configuration
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ q_swarm_experiment.argos   # ARGoS configuration
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ q_network.py               # Deep Q-Learning network
â”‚   â”œâ”€â”€ q_server.py                # Communication server
â”‚   â””â”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ models/
    â””â”€â”€ (trained models saved here)
```

## âš™ï¸ System Parameters

| Parameter | Value |
|-----------|-------|
| Grid Size | 20 Ã— 20 m |
| Number of Robots | 4 |
| Initial Spacing | 2 m |
| Velocity | 0.1 m/s |
| Max Episodes | 1000 |
| Goal Reward | +10 |
| Collision Penalty | -5 |
| Step Penalty | -0.1 |

## ğŸš€ Quick Start

### Prerequisites
- ARGoS3 installed
- CMake (3.10+)
- Python 3.8+
- PyTorch
- GCC/G++ compiler

### Installation Steps

1. **Install Python Dependencies**
```bash
cd python
pip install -r requirements.txt
```

2. **Build the C++ Controller**
```bash
cd controllers/q_swarm_controller
mkdir build
cd build
cmake ..
make
```

3. **Start the Q-Network Server**
```bash
cd python
python q_server.py
```

4. **Run ARGoS Simulation** (in another terminal)
```bash
argos3 -c experiments/q_swarm_experiment.argos
```

## ğŸ“Š What to Expect

- **Initial Behavior**: Robots move randomly, frequent collisions
- **After ~100 episodes**: Robots start avoiding walls and each other
- **After ~500 episodes**: Coordinated movement toward goal
- **After ~1000 episodes**: Efficient navigation with minimal collisions

## ğŸ§  Learning Process

1. Each robot observes its state (position + proximity sensors)
2. State is sent to Q-Network via socket
3. Q-Network predicts action (forward, left, right, stop)
4. Robot executes action in ARGoS
5. Reward is calculated based on outcome
6. Q-Network updates weights using experience replay
7. Process repeats for 1000 episodes

## ğŸ“ˆ Monitoring

- Watch the Qt-OpenGL visualization window
- Python console shows episode rewards
- Models are saved every 100 episodes

## ğŸ”§ Troubleshooting

See `BUILD_INSTRUCTIONS.md` for detailed troubleshooting guide.

## ğŸ“ License

Educational project for reinforcement learning demonstration.
